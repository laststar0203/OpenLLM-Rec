{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(\"/home/laststar/source/OpenLLM-Rec/source\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import easydict\n",
    "\n",
    "# jupyter didn't support argparse. so, I use 'easydict' module\n",
    "args = easydict.EasyDict({\n",
    "    ################\n",
    "    # Dataset\n",
    "    ################\n",
    "    'dataset_code': 'ml-100k', # ml-100k, beauty, games\n",
    "    'min_rating': 0,  # default: 0\n",
    "    'min_uc': 5,  # default: 5\n",
    "    'min_sc': 5,  # default: 5\n",
    "    'seed': 42,  # default: 42\n",
    "\n",
    "    ################\n",
    "    # Dataloader\n",
    "    ################\n",
    "    'train_batch_size': 64,  # default: 64\n",
    "    'val_batch_size': 64,  # default: 64\n",
    "    'test_batch_size': 64,  # default: 64\n",
    "    'num_workers': 0,  # default: 8\n",
    "    'sliding_window_size': 1.0,  # default: 1.0\n",
    "    'negative_sample_size': 10,  # default: 10\n",
    "\n",
    "    ################\n",
    "    # Trainer\n",
    "    ################\n",
    "    # optimization #\n",
    "    'device': 'cuda',  # default: 'cuda'  # choices: ['cpu', 'cuda']\n",
    "    'num_epochs': 500,  # default: 500\n",
    "    'optimizer': 'AdamW',  # default: 'AdamW'  # choices: ['AdamW', 'Adam']\n",
    "    'weight_decay': 0.01,  # default: None\n",
    "    'adam_epsilon': 1e-9,  # default: 1e-9\n",
    "    'momentum': None,  # default: None\n",
    "    'lr': 0.001,  # default: 0.001\n",
    "    'max_grad_norm': 5.0,  # default: 5.0\n",
    "    'enable_lr_schedule': True,  # default: True\n",
    "    'decay_step': 10000,  # default: 10000\n",
    "    'gamma': 1,  # default: 1\n",
    "    'enable_lr_warmup': True,  # default: True\n",
    "    'warmup_steps': 100,  # default: 100\n",
    "\n",
    "    # evaluation #\n",
    "    'val_strategy': 'iteration',  # default: 'iteration'  # choices: ['epoch', 'iteration']\n",
    "    'val_iterations': 500,  # default: 500  # only for iteration val_strategy\n",
    "    'early_stopping': True,  # default: True\n",
    "    'early_stopping_patience': 20,  # default: 20\n",
    "    'metric_ks': [1, 5, 10, 20, 50],  # default: [1, 5, 10, 20, 50]\n",
    "    'rerank_metric_ks': [1, 5, 10],  # default: [1, 5, 10]\n",
    "    'best_metric': 'Recall@10',  # default: 'Recall@10'\n",
    "    'rerank_best_metric': 'NDCG@10',  # default: 'NDCG@10'\n",
    "    'use_wandb': False,  # default: False\n",
    "\n",
    "    ################\n",
    "    # Retriever Model\n",
    "    ################\n",
    "    'model_code': 'bert',  # default: None\n",
    "    'bert_max_len': 100,  # default: 50\n",
    "    'bert_hidden_units': 256,  # default: 64\n",
    "    'bert_num_blocks': 2,  # default: 2\n",
    "    'bert_num_heads': 4,  # default: 2\n",
    "    'bert_head_size': 32,  # default: 32\n",
    "    'bert_dropout': 0.1,  # default: 0.2\n",
    "    'bert_mask_prob': 0.15,  # default: 0.25\n",
    "    \n",
    "    # bertrec\n",
    "    'train_negative_sampler_code': 'random',\n",
    "    'train_negative_sample_size': 0,\n",
    "    'train_negative_sampling_seed': 0,\n",
    "    'test_negative_sampler_code': 'random',\n",
    "    'test_negative_sample_size': 100,\n",
    "    'test_negative_sampling_seed': 98765,\n",
    "    'model_init_seed': 0,\n",
    "    'num_gpu': 1,\n",
    "    'optimizer': 'Adam',\n",
    "    'log_period_as_iter': 12800,\n",
    "    \n",
    "    ################\n",
    "    # LLM Model\n",
    "    ################\n",
    "    'llm_base_model': 'meta-llama/Llama-2-7b-hf',  # default: 'meta-llama/Llama-2-7b-hf'\n",
    "    'llm_base_tokenizer': 'meta-llama/Llama-2-7b-hf',  # default: 'meta-llama/Llama-2-7b-hf'\n",
    "    'llm_max_title_len': 32,  # default: 32\n",
    "    'llm_max_text_len': 1536,  # default: 1536\n",
    "    'llm_max_history': 20,  # default: 20\n",
    "    'llm_train_on_inputs': False,  # default: False\n",
    "    'llm_negative_sample_size': 19,  # default: 19  # 19 negative & 1 positive\n",
    "    'llm_system_template': \"Given user history in chronological order, recommend an item from the candidate pool with its index letter.\",  # default: \"Given user history in chronological order, recommend an item from the candidate pool with its index letter.\"\n",
    "    'llm_input_template': 'User history: {}; \\n Candidate pool: {}',  # default: 'User history: {}; \\n Candidate pool: {}'\n",
    "    'llm_load_in_4bit': True,  # default: True\n",
    "    'llm_retrieved_path': \"/home/laststar/data/model/OpenLLM-Rec\",  # default: None\n",
    "    'llm_cache_dir': None,  # default: None\n",
    "\n",
    "    ################\n",
    "    # Lora\n",
    "    ################\n",
    "    'lora_r': 8,  # default: 8\n",
    "    'lora_alpha': 32,  # default: 32\n",
    "    'lora_dropout': 0.05,  # default: 0.05\n",
    "    'lora_target_modules': ['q_proj', 'v_proj'],  # default: ['q_proj', 'v_proj']\n",
    "    'lora_num_epochs': 1,  # default: 1\n",
    "    'lora_val_iterations': 100,  # default: 100\n",
    "    'lora_early_stopping_patience': 20,  # default: 20\n",
    "    'lora_lr': 1e-4,  # default: 1e-4\n",
    "    'lora_micro_batch_size': 16,  # default: 16\n",
    "\n",
    "    #################\n",
    "    # Custom\n",
    "    #################\n",
    "    'alpaca_file': \"../source/data/dataloader/templates\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPORT_ROOT = \"/home/laststar/data/model/OpenLLM-Rec/bert\"\n",
    "MODEL_PARAMETER_PATH = \"/home/laststar/data/model/OpenLLM-Rec/bert/models/best_acc_model.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import data.datasets\n",
    "import data.dataloader\n",
    "from data.dataloader import *\n",
    "from data.datasets import *\n",
    "from model.bert import BERT4Rec\n",
    "from trainer.utils import AverageMeterSet\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already preprocessed. Skip preprocessing\n",
      "Negatives samples exist. Loading.\n",
      "Negatives samples exist. Loading.\n"
     ]
    }
   ],
   "source": [
    "train, val, test = dataloader_factory(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BERT4Rec(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device :  cuda\n"
     ]
    }
   ],
   "source": [
    "device = args.device\n",
    "print(\"device : \", device)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3770643/1386210373.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(MODEL_PARAMETER_PATH)['model_state_dict'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BERT4Rec(\n",
       "  (bert): BERT(\n",
       "    (embedding): BERTEmbedding(\n",
       "      (token): TokenEmbedding(3652, 256, padding_idx=0)\n",
       "      (position): PositionalEmbedding(\n",
       "        (pe): Embedding(100, 256)\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer_blocks): ModuleList(\n",
       "      (0-1): 2 x TransformerBlock(\n",
       "        (attention): MultiHeadedAttention(\n",
       "          (linear_layers): ModuleList(\n",
       "            (0-2): 3 x Linear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (output_linear): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (attention): Attention()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (feed_forward): PositionwiseFeedForward(\n",
       "          (w_1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "          (w_2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (activation): GELU(approximate='none')\n",
       "        )\n",
       "        (input_sublayer): SublayerConnection(\n",
       "          (norm): LayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (output_sublayer): SublayerConnection(\n",
       "          (norm): LayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (out): Linear(in_features=256, out_features=3651, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()\n",
    "model.load_state_dict(torch.load(MODEL_PARAMETER_PATH)['model_state_dict'])\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_meter_set = AverageMeterSet()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test BERT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seqs shape : torch.Size([64, 100])\n",
      "labels shape : torch.Size([64, 101])\n",
      "candidates shape : torch.Size([64, 101])\n"
     ]
    }
   ],
   "source": [
    "batch = None\n",
    "seqs = None\n",
    "candidates = None\n",
    "labels = None\n",
    "\n",
    "for batch in test:\n",
    "    batch = [x.to(device) for x in batch]\n",
    "    seqs, candidates, labels = batch\n",
    "    break\n",
    "\n",
    "print(f'seqs shape : {seqs.shape}')\n",
    "print(f'labels shape : {labels.shape}')\n",
    "print(f'candidates shape : {candidates.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "candidates : tensor([[2368,  610,  610,  ...,  610,  610,  610],\n",
      "        [1615,    1,    1,  ...,    1,    1,    1],\n",
      "        [3315,    2,    2,  ...,    2,    2,    2],\n",
      "        ...,\n",
      "        [ 470,   61,   61,  ...,   61,   61,   61],\n",
      "        [ 322,   62,   62,  ...,   62,   62,   62],\n",
      "        [ 853,   63,   63,  ...,   63,   63,   63]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(f\"candidates : {candidates}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores shape : torch.Size([64, 100, 3651])\n"
     ]
    }
   ],
   "source": [
    "scores = model(seqs)  # B x T x V\n",
    "print(f\"scores shape : {scores.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores shape : torch.Size([64, 3651])\n",
      "scores : tensor([[-1.2499,  2.2739, -0.9554,  ..., -0.6270, -0.8693, -1.3612],\n",
      "        [-1.2320,  2.3361, -1.0500,  ..., -0.7096, -0.9411, -1.3691],\n",
      "        [-1.2026,  1.5721,  2.4841,  ...,  2.0266,  1.3509, -0.6006],\n",
      "        ...,\n",
      "        [-1.3748,  2.1765, -0.5572,  ..., -0.2826, -0.5927, -1.3798],\n",
      "        [-0.3150, -0.3248,  2.3508,  ...,  1.8745,  1.5297,  0.2448],\n",
      "        [-1.7066,  2.3171,  0.4470,  ...,  0.5506,  0.0307, -1.4714]],\n",
      "       device='cuda:0', grad_fn=<SliceBackward0>)\n"
     ]
    }
   ],
   "source": [
    "scores = scores[:, -1, :]  # B x V\n",
    "print(f\"scores shape : {scores.shape}\")\n",
    "print(f\"scores : {scores}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "gather(dim, index)는 dim 차원에서 index에 해당하는 값만 선택합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores shape : torch.Size([64, 101])\n",
      "scores : tensor([[-0.6026,  0.1785,  0.1785,  ...,  0.1785,  0.1785,  0.1785],\n",
      "        [-0.3160,  2.3361,  2.3361,  ...,  2.3361,  2.3361,  2.3361],\n",
      "        [ 0.8027,  2.4841,  2.4841,  ...,  2.4841,  2.4841,  2.4841],\n",
      "        ...,\n",
      "        [ 2.7742,  0.0594,  0.0594,  ...,  0.0594,  0.0594,  0.0594],\n",
      "        [ 1.5143, -1.1689, -1.1689,  ..., -1.1689, -1.1689, -1.1689],\n",
      "        [ 2.5579,  0.5730,  0.5730,  ...,  0.5730,  0.5730,  0.5730]],\n",
      "       device='cuda:0', grad_fn=<GatherBackward0>)\n"
     ]
    }
   ],
   "source": [
    "scores = scores.gather(1, candidates)  # B x C\n",
    "print(f\"scores shape : {scores.shape}\")\n",
    "print(f\"scores : {scores}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 0, 0,  ..., 0, 0, 0],\n",
       "        [1, 0, 0,  ..., 0, 0, 0],\n",
       "        [1, 0, 0,  ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [1, 0, 0,  ..., 0, 0, 0],\n",
       "        [1, 0, 0,  ..., 0, 0, 0],\n",
       "        [1, 0, 0,  ..., 0, 0, 0]], device='cuda:0')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recalls_and_ndcgs_for_ks(scores, labels, ks):\n",
    "    metrics = {}\n",
    "\n",
    "    scores = scores\n",
    "    labels = labels\n",
    "    answer_count = labels.sum(1)\n",
    "\n",
    "    labels_float = labels.float()\n",
    "    print(labels_float)\n",
    "    rank = (-scores).argsort(dim=1)\n",
    "    print(rank)\n",
    "    cut = rank\n",
    "    for k in sorted(ks, reverse=True):\n",
    "       cut = cut[:, :k]\n",
    "       hits = labels_float.gather(1, cut)\n",
    "       metrics['Recall@%d' % k] = \\\n",
    "           (hits.sum(1) / torch.min(torch.Tensor([k]).to(labels.device), labels.sum(1).float())).mean().cpu().item()\n",
    "\n",
    "       position = torch.arange(2, 2+k)\n",
    "       weights = 1 / torch.log2(position.float())\n",
    "       dcg = (hits * weights.to(hits.device)).sum(1)\n",
    "       idcg = torch.Tensor([weights[:min(int(n), k)].sum() for n in answer_count]).to(dcg.device)\n",
    "       ndcg = (dcg / idcg).mean()\n",
    "       metrics['NDCG@%d' % k] = ndcg.cpu().item()\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n",
      "tensor([[  1,   2,   3,  ...,  99, 100,   0],\n",
      "        [  1,   2,   3,  ...,  99, 100,   0],\n",
      "        [  1,   2,   3,  ...,  99, 100,   0],\n",
      "        ...,\n",
      "        [  0,   1,   2,  ...,  98,  99, 100],\n",
      "        [  0,   1,   2,  ...,  98,  99, 100],\n",
      "        [  0,   1,   2,  ...,  98,  99, 100]], device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Recall@50': 0.65625,\n",
       " 'NDCG@50': 0.65625,\n",
       " 'Recall@20': 0.65625,\n",
       " 'NDCG@20': 0.65625,\n",
       " 'Recall@10': 0.65625,\n",
       " 'NDCG@10': 0.65625,\n",
       " 'Recall@5': 0.65625,\n",
       " 'NDCG@5': 0.65625,\n",
       " 'Recall@1': 0.65625,\n",
       " 'NDCG@1': 0.65625}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recalls_and_ndcgs_for_ks(scores, labels, args.metric_ks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
