{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e442f14-c702-4794-87ad-a52004c30409",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(\"../source\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d41ad304-30e0-4bb9-86c6-d8e48822529a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69381e63-851a-4e13-9e3a-d7eea36a47e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import easydict\n",
    "\n",
    "# jupyter didn't support argparse. so, I use 'easydict' module\n",
    "args = easydict.EasyDict({\n",
    "    ################\n",
    "    # Dataset\n",
    "    ################\n",
    "    'dataset_code': 'ml-100k', # ml-100k, beauty, games\n",
    "    'min_rating': 0,  # default: 0\n",
    "    'min_uc': 5,  # default: 5\n",
    "    'min_sc': 5,  # default: 5\n",
    "    'seed': 42,  # default: 42\n",
    "\n",
    "    ################\n",
    "    # Dataloader\n",
    "    ################\n",
    "    'train_batch_size': 64,  # default: 64\n",
    "    'val_batch_size': 64,  # default: 64\n",
    "    'test_batch_size': 64,  # default: 64\n",
    "    'num_workers': 0,  # default: 8\n",
    "    'sliding_window_size': 1.0,  # default: 1.0\n",
    "    'negative_sample_size': 10,  # default: 10\n",
    "\n",
    "    ################\n",
    "    # Trainer\n",
    "    ################\n",
    "    # optimization #\n",
    "    'device': 'cuda',  # default: 'cuda'  # choices: ['cpu', 'cuda']\n",
    "    'num_epochs': 500,  # default: 500\n",
    "    'optimizer': 'AdamW',  # default: 'AdamW'  # choices: ['AdamW', 'Adam']\n",
    "    'weight_decay': 0.01,  # default: None\n",
    "    'adam_epsilon': 1e-9,  # default: 1e-9\n",
    "    'momentum': None,  # default: None\n",
    "    'lr': 0.001,  # default: 0.001\n",
    "    'max_grad_norm': 5.0,  # default: 5.0\n",
    "    'enable_lr_schedule': True,  # default: True\n",
    "    'decay_step': 10000,  # default: 10000\n",
    "    'gamma': 1,  # default: 1\n",
    "    'enable_lr_warmup': True,  # default: True\n",
    "    'warmup_steps': 100,  # default: 100\n",
    "\n",
    "    # evaluation #\n",
    "    'val_strategy': 'iteration',  # default: 'iteration'  # choices: ['epoch', 'iteration']\n",
    "    'val_iterations': 500,  # default: 500  # only for iteration val_strategy\n",
    "    'early_stopping': True,  # default: True\n",
    "    'early_stopping_patience': 20,  # default: 20\n",
    "    'metric_ks': [1, 5, 10, 20, 50],  # default: [1, 5, 10, 20, 50]\n",
    "    'rerank_metric_ks': [1, 5, 10],  # default: [1, 5, 10]\n",
    "    'best_metric': 'Recall@10',  # default: 'Recall@10'\n",
    "    'rerank_best_metric': 'NDCG@10',  # default: 'NDCG@10'\n",
    "    'use_wandb': False,  # default: False\n",
    "\n",
    "    ################\n",
    "    # Retriever Model\n",
    "    ################\n",
    "    'model_code': 'lru',  # default: None\n",
    "    'bert_max_len': 50,  # default: 50\n",
    "    'bert_hidden_units': 64,  # default: 64\n",
    "    'bert_num_blocks': 2,  # default: 2\n",
    "    'bert_num_heads': 2,  # default: 2\n",
    "    'bert_head_size': 32,  # default: 32\n",
    "    'bert_dropout': 0.2,  # default: 0.2\n",
    "    'bert_attn_dropout': 0.2,  # default: 0.2\n",
    "    'bert_mask_prob': 0.25,  # default: 0.25\n",
    "\n",
    "    ################\n",
    "    # LLM Model\n",
    "    ################\n",
    "    'llm_base_model': 'meta-llama/Llama-2-7b-hf',  # default: 'meta-llama/Llama-2-7b-hf'\n",
    "    'llm_base_tokenizer': 'meta-llama/Llama-2-7b-hf',  # default: 'meta-llama/Llama-2-7b-hf'\n",
    "    'llm_max_title_len': 32,  # default: 32\n",
    "    'llm_max_text_len': 1536,  # default: 1536\n",
    "    'llm_max_history': 20,  # default: 20\n",
    "    'llm_train_on_inputs': False,  # default: False\n",
    "    'llm_negative_sample_size': 19,  # default: 19  # 19 negative & 1 positive\n",
    "    'llm_system_template': \"Given user history in chronological order, recommend an item from the candidate pool with its index letter.\",  # default: \"Given user history in chronological order, recommend an item from the candidate pool with its index letter.\"\n",
    "    'llm_input_template': 'User history: {}; \\n Candidate pool: {}',  # default: 'User history: {}; \\n Candidate pool: {}'\n",
    "    'llm_load_in_4bit': True,  # default: True\n",
    "    'llm_retrieved_path': None,  # default: None\n",
    "    'llm_cache_dir': None,  # default: None\n",
    "\n",
    "    ################\n",
    "    # Lora\n",
    "    ################\n",
    "    'lora_r': 8,  # default: 8\n",
    "    'lora_alpha': 32,  # default: 32\n",
    "    'lora_dropout': 0.05,  # default: 0.05\n",
    "    'lora_target_modules': ['q_proj', 'v_proj'],  # default: ['q_proj', 'v_proj']\n",
    "    'lora_num_epochs': 1,  # default: 1\n",
    "    'lora_val_iterations': 100,  # default: 100\n",
    "    'lora_early_stopping_patience': 20,  # default: 20\n",
    "    'lora_lr': 1e-4,  # default: 1e-4\n",
    "    'lora_micro_batch_size': 16,  # default: 16\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "52eda9cc-9e5a-4911-904f-fac10c7c7bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.datasets import dataset_factory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cad09f92-194e-4781-87d8-8acef73e13fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset_factory(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "48a88be6-989f-4c5e-b603-931cd705b716",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already preprocessed. Skip preprocessing\n"
     ]
    }
   ],
   "source": [
    "dataset = dataset.load_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "560a5996-94bb-4efa-bdb5-58e4629259ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_count : 610\n",
      "item_count : 3650\n",
      "num_users : 610\n",
      "num_items : 3650\n",
      "max_len : 50\n",
      "sliding_size : 1.0\n"
     ]
    }
   ],
   "source": [
    "train = dataset['train']\n",
    "val = dataset['val']\n",
    "test = dataset['test']\n",
    "umap = dataset['umap']\n",
    "smap = dataset['smap']\n",
    "rng = np.random\n",
    "\n",
    "user_count = len(umap)\n",
    "item_count = len(smap)\n",
    "\n",
    "num_users = user_count\n",
    "num_items = item_count\n",
    "max_len = args.bert_max_len\n",
    "sliding_size = args.sliding_window_size\n",
    "\n",
    "print(f\"user_count : {user_count}\")\n",
    "print(f\"item_count : {item_count}\")\n",
    "print(f\"num_users : {num_users}\")\n",
    "print(f\"num_items : {num_items}\")\n",
    "print(f\"max_len : {max_len}\")\n",
    "print(f\"sliding_size : {sliding_size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc2b1531-93e2-4103-b2c6-c2ce1d665080",
   "metadata": {},
   "source": [
    "## Train Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0dda8ce-9697-4969-a411-8dc0976a1418",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "15706f7f-98b9-4886-a33f-91d9226c226a",
   "metadata": {},
   "source": [
    "## Test Loader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "781c80df-8e11-4301-b28d-b2484ed77577",
   "metadata": {},
   "source": [
    "최종형태: Seq: train(N개) + val(1개) -> 총 50개(**max_len**) / target: test(1개)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c12cf520-4fd8-43b0-bb30-d510ec41b2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "u2seq = train\n",
    "u2val = val\n",
    "u2answer = test\n",
    "users = [u for u in sorted(u2seq.keys()) if len(u2val[u]) > 0 and len(u2answer[u]) > 0]\n",
    "max_len = max_len\n",
    "rng = rng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "98be5de6-f7de-4a64-b71f-8d7e688f8a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bb1a667a-a79b-4820-9430-a64f995861fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "user = users[index]\n",
    "# user에 대하여 train sequence 와 val sequence를 병합\n",
    "seq = u2seq[user] + u2val[user]\n",
    "answer = u2answer[user]\n",
    "\n",
    "# 전체 시퀸스에서 max_len 까지만 추출\n",
    "seq = seq[-max_len:]\n",
    "\n",
    "# 패딩 적용\n",
    "padding_len = max_len - len(seq)\n",
    "seq = [0] * padding_len + seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "03e4e8b3-6be0-4d35-a5b7-d6874b3517da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1538,  708,  857, 1496, 1863,  868,  966, 1687, 1689,  904,  924, 1597,\n",
       "        1688, 1725, 1690,  798, 2100, 1104, 1989, 1113, 2060, 1500,  911,  700,\n",
       "         875,  137, 1473,  916,  886,  855, 2256, 1900,  470,   47, 1511, 1968,\n",
       "         429, 2830,  796,  873,  125, 2135,  590,  944, 1916,  131, 1024,  452,\n",
       "        1610, 1304])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.LongTensor(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b76dc78e-2f0b-4536-bb9b-ba5523cf6db5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1615])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.LongTensor(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a34a03-57bb-4ee9-af0c-2748383f5ee5",
   "metadata": {},
   "source": [
    "## Validation Loader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b11ea61b-0503-42ae-9226-a31daa813a11",
   "metadata": {},
   "source": [
    "Test Loader 전처리 방식과 거의 동일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2399491d-e10a-428e-94b1-f7a9d4bc413c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
